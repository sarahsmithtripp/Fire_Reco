import rioxarray
import geopandas as gpd
import numpy as np
from geocube.api.core import make_geocube
import pandas as pd
import dask as da
"""
source the working functions script 
"""
exec(open('F:/Fire_Recovery/Code_Workflow/Python/Working_Functions.py').read())
#check that maks_season is in the namespace return error if not
'mask_season' in locals()
"""
Read in large fire database and the disturbance raster
"""
#save location 
out = 'F:/Fire_Recovery'
#load national large fire database (fires > 200 ha)
nlfd = gpd.read_file('F:/Fire_Recovery/NLFD/NFDB_poly_20210707_large_fires.shp')
# read in dist raster (NTEMS Greatest Change Year 1986-2022)
source = '//Frst-frm-2232b/g/sarah/mosaiced'
## laod in the disturbance raster in chunks 
dist = rioxarray.open_rasterio('D:/C2C_Updated/change/SRef_Greatest_Change_Year.dat', chunks = (4000,4000))
## read in the regrowth raster
regrowth = rioxarray.open_rasterio(source +'/change_metrics/SRef_PostChange_evolution_rate.dat')

## concatenate 3 columns: year, month and day into one data.time column 
# subset month and day so that they are greater than zero
nlfd['FIRE_DATE'] = nlfd['YEAR'].astype(str) + '-' + nlfd['MONTH'].astype(str) +'-' + nlfd['DAY'].astype(str)
## subset to values that have month recordings 
nlfd_rec = nlfd[nlfd['DAY'] > 0]
nlfd_rec['FIRE_DATE'] = pd.to_datetime(nlfd_rec['FIRE_DATE'])
nlfd_rec['DOY'] = nlfd_rec['FIRE_DATE'].dt.dayofyear
#change the coordinate system of the shapefile to match the raster
nlfd_crs = nlfd_rec.to_crs(dist.rio.crs)
# check the crs of the shapefile and the raster are the same 
nlfd_crs.crs == dist.rio.crs

"""
Mask by day and get the recovery values for each month
"""
np.unique(nlfd_crs['DOY'])
## count the proportions that has not DOY observations
nlfd_crs['DOY'].isna().sum()/len(nlfd_crs['DOY'])
### get the names of nlfd
nlfd_crs.columns
# create a list for days of the year
doy = list(range(1,356))
def mask_day(nlfd_in, dist, day):
    #filter shapefile to a subset of days defined in the function
    nlfd_day = nlfd_in[nlfd_in['DOY'] == day]
    # turn this into a raster with values from YEAR in the shapefile
    # USing geocube turn the nlfd_day into a raster
    nlfd_day = make_geocube(vector_data=nlfd_day, 
                            measurements=["YEAR"], like=dist, 
                            fill = 0)
    # expand to make a binary raster with the number of years 
    nlfd_exp = nlfd_day.expand_dims(dim = 'YEAR')
    regrowth_masked = regrowt
    nlfd_year = nlfd_day.YEAR.round()
    # # convert to a binary mask when nlfd_year does not equal dist year
    dist_late = dist - 1
    dist_mask = dist.where(nlfd_year == dist or nlfd == dist_late, other = 0)
    regrowth_dist_mask = regrowth_masked.where(dist_mask != 0, other = -999)
    dist_mask.rio.to_raster('D:/C2C_Updated/test.tif')
    return nlfd_day

regrowth_day_list = []
for day in doy:
     print(day)
     mask = mask_day(nlfd_crs, dist, day)
     #write mask to a file 
     regrowth_day = regrowth.where(mask(), other = np.nan)
     #turn the raster into a numpy array
     regrowth_day_v = regrowth_day.values
    #remove the nan values
     regrowth_day_v = regrowth_day_v[~np.isnan(regrowth_day_v)]
    ## add day of the year to the dataframe
     regrowth_day_v['DOY'] = day
     # add to a list of dataframes
     regrowth_day_list.append(regrowth_day_v)

"""
DASKIFY 
update code above to work with DASK 
"""


import dask.array as da
from geocube.api.core import make_geocube
import rioxarray
import geopandas as gpd

def mask_day(nlfd_in, dist, day):
    # Assuming nlfd_in is a GeoDataFrame
    # Filter shapefile to a subset for the given day
    nlfd_day = nlfd_in[nlfd_in['DOY'] == day]

    # Turn the filtered GeoDataFrame (nlfd_day) into a raster
    # Note: Adjust 'like' parameter to match your 'dist' raster's dimensions, CRS, etc.
    # This step assumes 'dist' has been loaded with rioxarray and chunks have been defined
    nlfd_day_raster = make_geocube(vector_data=nlfd_day, measurements=["YEAR"], like=dist.rio.write_crs(nlfd_in.crs.to_string()))

    # Convert to xarray DataArray and round values to the nearest year
    nlfd_year = nlfd_day_raster['YEAR'].round()

    # Ensure dist is chunked with Dask for efficient computation
    # This step is necessary if 'dist' was not already chunked when loaded
    if not isinstance(dist.data, da.Array):
        dist = dist.rio.reproject(dist.rio.crs, resolution=(dist.rio.resolution()[0], dist.rio.resolution()[1])).chunk({'x': -1, 'y': -1})

    # Mask out values in 'dist' that are not equal to the year in 'nlfd_year'
    # Using where operation with Dask for lazy evaluation
    dist_mask = dist.where(dist == nlfd_year, other=0)  # or drop=True to exclude non-matching pixels

    return dist_mask
